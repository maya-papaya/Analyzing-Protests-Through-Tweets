{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfF-AtObtry0"
      },
      "source": [
        "# Step 3: Conducting Analysis\n",
        "\n",
        "Now, we will perform the final step of this project: conducting our analysis!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdUaHffady1j"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMBNTBpxekH4"
      },
      "source": [
        "First, we have to upload our datasets and convert them to a Dataset object format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmZdYATmd3ew"
      },
      "outputs": [],
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json\n",
        "\n",
        "! kaggle datasets download adhok93/inauguration-and-womensmarch-tweets\n",
        "! unzip inauguration-and-womensmarch-tweets.zip\n",
        "\n",
        "! kaggle datasets download prathamsharma123/farmers-protest-tweets-dataset-csv\n",
        "! unzip farmers-protest-tweets-dataset-csv.zip\n",
        "\n",
        "! pip install transformers datasets\n",
        "! pip install keybert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5oO0SW7eHTg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "womenmarch = pd.read_csv(\"womenmarch.csv\",encoding='ISO-8859-1')\n",
        "womenmarch = womenmarch.to_dict()\n",
        "for col in womenmarch:\n",
        "  womenmarch[col] = list(womenmarch[col].values())\n",
        "womenmarch = Dataset.from_pandas(pd.DataFrame(data=womenmarch))\n",
        "\n",
        "farmers = pd.read_csv(\"tweets.csv\",encoding='ISO-8859-1')\n",
        "farmers['date'] = pd.to_datetime(farmers['date'])\n",
        "farmers.sort_values(by='date', inplace = True)\n",
        "farmers = farmers.to_dict()\n",
        "for col in farmers:\n",
        "  farmers[col] = list(farmers[col].values())\n",
        "farmers = Dataset.from_pandas(pd.DataFrame(data=farmers))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knTQVBFoe7wM"
      },
      "source": [
        "We also have to load our fine-tuned model and a KeyBERT model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fi4RTqAYqv-r"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "from keybert import KeyBERT\n",
        "\n",
        "sentiment_model = AutoModelForSequenceClassification.from_pretrained('mayapapaya/Sentiment-Analyzer')\n",
        "keyword_model = KeyBERT()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4o9t9PHeqwq"
      },
      "source": [
        "Now, we can start conducting our analysis!\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Analysis\n",
        "\n",
        "In this analysis, I am creating three different functions, each with their own task: public sentiment, public sentiment within a certain time period, and keyword extracting.\n",
        "\n",
        "\n",
        "### Function 1: Public Sentiment\n",
        "This function is to determine the majority sentiment towards the movement.\n",
        "\n",
        "*Parameters: dataset, tweet_index*\n",
        "\n",
        "*Return Value: String that specifies the sentiment (positive, negative, or neutral)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGbyTqO2eTCZ"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "def public_sentiment(dataset, tweet_index):\n",
        "  positive, negative, neutral = 0, 0, 0\n",
        "\n",
        "  # Input the tweet text into the model\n",
        "  generator = pipeline('sentiment-analysis',\n",
        "                    model=sentiment_model,\n",
        "                    tokenizer='bert-base-uncased')\n",
        "\n",
        "  # Determine the tweet text's sentiment\n",
        "  for row in dataset:\n",
        "    sentiment = generator(row[tweet_index], max_length=512, truncation=True)\n",
        "    if sentiment[0]['label'] == \"LABEL_2\":\n",
        "      positive += 1\n",
        "    if sentiment[0]['label'] == \"LABEL_1\":\n",
        "      neutral += 1\n",
        "    if sentiment[0]['label'] == \"LABEL_0\":\n",
        "      negative += 1\n",
        "\n",
        "  \"\"\"\n",
        "  positives = [sentiment for sentiment in sentiments if sentiment[0]['label'] == \"LABEL_2\"]\n",
        "  neutrals = [sentiment for sentiment in sentiments if sentiment[0]['label'] == \"LABEL_1\"]\n",
        "  negatives = [sentiment for sentiment in sentiments if sentiment[0]['label'] == \"LABEL_0\"]\n",
        "\n",
        "  positive = len(positives)\n",
        "  negative = len(negatives)\n",
        "  neutral = len(neutrals)\n",
        "  \"\"\"\n",
        "\n",
        "  # Return the percentages of each sentiment and the total number of tweets\n",
        "  return [float(positive/len(dataset)) * 100, float(negative/len(dataset)) * 100, float(neutral/len(dataset)) * 100, len(dataset)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ei9O9Vneh0kk"
      },
      "source": [
        "### Function 2: Public Sentiment within a Certain Time Period\n",
        "\n",
        "This function is to determine whether a certain protest (for example, a riot) affects how the movement is viewed.\n",
        "\n",
        "*Parameters: start_date, end_date (both are datetime objects), dataset, tweet_index, time_index*\n",
        "\n",
        "*Return Value: String that specifies the sentiment (positive, negative, or neutral)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJDpH9rVhzD4"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from datasets import Dataset\n",
        "\n",
        "def public_sentiment_time(start_date, end_date, dataset, tweet_index, time_index):\n",
        "\n",
        "  start_date = datetime.strptime(start_date, '%Y-%m-%d %H:%M:%S%z')\n",
        "  end_date = datetime.strptime(end_date, '%Y-%m-%d %H:%M:%S%z')\n",
        "\n",
        "  # Checking if dates exist within dataset\n",
        "  if not(start_date >= dataset[0][time_index] or end_date <= dataset[-1][time_index]):\n",
        "    print(\"Date does not exist within dataset\")\n",
        "    return None\n",
        "\n",
        "  # Segment dataset into the specified time period\n",
        "  start_date_index = 0\n",
        "  end_date_index = len(dataset) - 1\n",
        "\n",
        "  for i, row in enumerate(dataset):\n",
        "    if (i+1) != len(dataset):\n",
        "      if dataset[i][time_index] <= start_date < dataset[i+1][time_index]:\n",
        "        start_date_index = i+1\n",
        "      elif dataset[i][time_index] < end_date <= dataset[i+1][time_index]:\n",
        "        end_date_index = i\n",
        "\n",
        "  print(dataset[start_date_index])\n",
        "  print(dataset[end_date_index])\n",
        "\n",
        "  seg_dataset = dataset[start_date_index:end_date_index]\n",
        "  seg_dataset = Dataset.from_dict(seg_dataset)\n",
        "\n",
        "  return public_sentiment(seg_dataset, tweet_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kdUl5wv5dDv"
      },
      "source": [
        "### Function 3: Keyword Extractor\n",
        "\n",
        "This function is to determine whether the issue itself is being spread, or whether the protester’s actions distract from that.\n",
        "\n",
        "*Parameters: keywords (a list that holds all the keyword variations considered central to the movement (e.g. abortion keywords --> “abortion”, “reproductive rights”, “pro-life”, “pro-choice\", etc.), dataset*\n",
        "\n",
        "*Return Value: dictionary where keys are keywords and values are the percentages they appeared*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6IMLOryiOJZ"
      },
      "outputs": [],
      "source": [
        "def keyword_extractor(dataset, keywords):\n",
        "  related = 0\n",
        "\n",
        "  for tweet in dataset:\n",
        "    # Input the tweet text into the model\n",
        "    tweet_keywords = keyword_model.extract_keywords(tweet, keyphrase_ngram_range=(1, 2))\n",
        "    tweet_keywords = [x[0] for x in tweet_keywords]\n",
        "\n",
        "    # See if the tweet's keywords are related to the issue\n",
        "    for tweet_keyword in tweet_keywords:\n",
        "      if tweet_keyword in keywords:\n",
        "        related += 1\n",
        "\n",
        "  return [related/len(dataset)*100, len(dataset)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5LpaptYIvDZ"
      },
      "source": [
        "Now let's analyze our datasets using these functions!\n",
        "\n",
        "## WomensMarch Analysis\n",
        "\n",
        "We'll start with the #WomensMarch dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_GNvUuGHB6m"
      },
      "outputs": [],
      "source": [
        "print(\"Public Sentiment:\")\n",
        "print(public_sentiment(womenmarch, 'text'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PatcHcJeLhL8"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Func 1 Output:\n",
        "\n",
        "Positive Tweets: 37.00666666666667 %\n",
        "Negative Tweets: 18.593333333333334 %\n",
        "Neutral Tweets: 44.4 %\n",
        "\n",
        "Total Tweets: 15,000\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2tUKR_NtBqE"
      },
      "outputs": [],
      "source": [
        "print(\"Keyword Usage: \")\n",
        "print(keyword_extractor(womenmarch['text'], [\"riot\", \"nuisance\", \"traffic\", \"problem\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4V4ZFcxlI5SU"
      },
      "source": [
        "```\n",
        "# Func 3 Output:\n",
        "\n",
        "Keywords: \"riot\", \"nuisance\", \"traffic\", \"problem\"\n",
        "Percentage: 0.0 %\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrqmFMRDZsY4"
      },
      "source": [
        "## The Indian Farmers' Protest Analysis\n",
        "\n",
        "Now, we'll look at our second dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oes8mtiHEobt"
      },
      "outputs": [],
      "source": [
        "print(\"Public Sentiment:\")\n",
        "print(public_sentiment(farmers, 'renderedContent'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JbZSA3qLsf_"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Func 1 Output:\n",
        "\n",
        "Positive Tweets: 24.312463806604626 %\n",
        "Negative Tweets: 34.93026892845419 %\n",
        "Neutral Tweets: 40.75726726494119 %\n",
        "\n",
        "Total Tweets: 1,084,452\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4pd4m8Mj8-X"
      },
      "outputs": [],
      "source": [
        "start_date = \"2020-11-29 00:00:00+00:00\"\n",
        "end_date = \"2021-03-22 00:00:00+00:00\"\n",
        "print(\"Public Sentiment between \" + start_date + \" and \" + end_date + \": \")\n",
        "print(public_sentiment_time(start_date, end_date, farmers, 'renderedContent', 'date'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eu3CZWSLxmq"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Func 2 Output Between 11-29-2020 and 03-22-2021:\n",
        "\n",
        "Positive Tweets: 25.4336761614079 %\n",
        "Negative Tweets: 34.31111038955768 %\n",
        "Neutral Tweets: 40.25521344903443 %\n",
        "\n",
        "Total Tweets: 615,955\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oe_U8oaJHHTR"
      },
      "outputs": [],
      "source": [
        "start_date = \"2021-11-05 00:00:00+00:00\"\n",
        "end_date = \"2021-11-21 00:00:00+00:00\"\n",
        "print(\"Public Sentiment between \" + start_date + \" and \" + end_date + \": \")\n",
        "print(public_sentiment_time(start_date, end_date, farmers, 'renderedContent', 'date'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg3kDR4HL8ZY"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Func 2 Output Between 11-05-2021 and 11-21-2021::\n",
        "\n",
        "Positive Tweets: 27.842227378190255 %\n",
        "Negative Tweets: 33.75259494443766 %\n",
        "Neutral Tweets: 38.40517767737208 %\n",
        "\n",
        "Total Tweets: 24,567\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TFcdMdsiyza3"
      },
      "outputs": [],
      "source": [
        "start_date = \"2021-01-26 00:00:00+00:00\"\n",
        "end_date = \"2021-02-01 00:00:00+00:00\"\n",
        "print(\"Public Sentiment between \" + start_date + \" and \" + end_date + \": \")\n",
        "print(public_sentiment_time(start_date, end_date, farmers, 'renderedContent', 'date'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7X0EllRZMHWE"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Func 2 Output Between 01-26-2021 and 02-01-2021:\n",
        "\n",
        "Positive Tweets: 13.413878562577446 %\n",
        "Negative Tweets: 48.213548120611314 %\n",
        "Neutral Tweets: 38.372573316811234 %\n",
        "\n",
        "Total Tweets: 38,736\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUilu8YRvW0S"
      },
      "outputs": [],
      "source": [
        "print(\"Keyword Usage: \")\n",
        "print(keyword_extractor(farmers['renderedContent'], [\"riot\", \"nuisance\", \"traffic\", \"problem\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-lpBSUnZ2Q1"
      },
      "source": [
        "```\n",
        "# Func 3 Output:\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J8naLxOMP1V"
      },
      "source": [
        "And we have now finished conducting our analysis!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyP1fIyqun4Jtd8H2Ttt6J7L"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}